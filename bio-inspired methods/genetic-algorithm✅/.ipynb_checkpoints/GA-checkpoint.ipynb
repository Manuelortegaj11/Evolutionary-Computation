{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684b6b486bc4a599",
   "metadata": {},
   "source": [
    "# Algoritmo Genético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07bd81e1-a53a-4ee2-886e-cc45452939bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_var' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1913351/3948474214.py\", line 163, in single_run\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/optimize.py\", line 67, in minimize\n    res = algorithm.run()\n          ^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/algorithm.py\", line 138, in run\n    self.next()\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/algorithm.py\", line 154, in next\n    infills = self.infill()\n              ^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/algorithm.py\", line 186, in infill\n    infills = self._initialize_infill()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/algorithms/base/genetic.py\", line 75, in _initialize_infill\n    pop = self.initialization.do(self.problem, self.pop_size, algorithm=self)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/initialization.py\", line 32, in do\n    pop = self.sampling(problem, n_samples, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/operator.py\", line 27, in __call__\n    out = self.do(problem, elem, *args, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/daztan/miniconda3/lib/python3.12/site-packages/pymoo/core/sampling.py\", line 35, in do\n    val = self._do(problem, n_samples, **kwargs)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_1913351/3948474214.py\", line 74, in _do\nNameError: name 'n_var' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m pop_size \u001b[38;5;129;01min\u001b[39;00m block1_pop_size:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m max_gen \u001b[38;5;129;01min\u001b[39;00m block1_max_gen:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m                 all_results.extend(\u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_mutate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_cross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBloque 1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapacidades\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemanda\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p_mutate \u001b[38;5;129;01min\u001b[39;00m block2_p_mutate:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p_cross \u001b[38;5;129;01min\u001b[39;00m block2_p_cross:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 185\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(p_mutate, p_cross, pop_size, max_gen, block_name, data, N, capacidades, xl, xu, demanda, runs)\u001b[39m\n\u001b[32m    172\u001b[39m     iterations = ga.history[-\u001b[32m1\u001b[39m].n_gen \u001b[38;5;28;01mif\u001b[39;00m ga.history \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    174\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m'\u001b[39m: block_name,\n\u001b[32m    175\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mT_mutacion\u001b[39m\u001b[33m'\u001b[39m: p_mutate,\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_run\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_mutate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_cross\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'n_var' is not defined"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scripts.queso_model import model_vars, model_data, objective_func, balance, alloc_df\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.core.crossover import Crossover\n",
    "from pymoo.core.mutation import Mutation\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.termination.default import DefaultSingleObjectiveTermination\n",
    "from pymoo.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Escenario 1\n",
    "folder = './data/escenario_1/'\n",
    "demanda = 60  # Aproximadamente el 26% de la capacidad total (232.625), adecuada para un escenario pequeño.\n",
    "\n",
    "# Escenario 2\n",
    "#folder = './data/escenario_2/'\n",
    "#demanda = 12000  # Aproximadamente el 78% de la capacidad total (15339), refleja la alta capacidad disponible.\n",
    "\n",
    "# Escenario 3\n",
    "#folder = './data/escenario_3/'\n",
    "#demanda = 80  # Aproximadamente el 70% de la capacidad total (114), balancea la baja disponibilidad de stock y potencial.\n",
    "\n",
    "# Escenario 4\n",
    "#folder = './data/escenario_4/'\n",
    "#demanda = 50000  # Aproximadamente el 86% de la capacidad total (58366), desafía a los algoritmos con alta demanda y muchos centros.\n",
    "\n",
    "info_acopios = 'centros_acopio.xlsx'\n",
    "costo_transporte = 'costos_transporte.xlsx'\n",
    "tiempo_transporte = 'tiempos_transporte.xlsx'\n",
    "\n",
    "archivos = {\n",
    "    'info_acopios': info_acopios,\n",
    "    'costo_transporte': costo_transporte,\n",
    "    'tiempo_transporte': tiempo_transporte,\n",
    "}\n",
    "\n",
    "data = model_data(archivos, demanda, folder=folder)  # ctiempo ahora se calcula como 10% del precio, dentro.\n",
    "\n",
    "N, seed, capacidades = model_vars(data['params_df'])\n",
    "\n",
    "\n",
    "xl = np.zeros(capacidades.shape[0])\n",
    "xu = capacidades\n",
    "\n",
    "class Queso(ElementwiseProblem):\n",
    "    def __init__(self, data, N, demanda):\n",
    "        super().__init__(\n",
    "            n_var=len(capacidades),\n",
    "            n_obj=1,\n",
    "            n_eq_constr=1,\n",
    "            xl=xl,\n",
    "            xu=xu\n",
    "        )\n",
    "        self.data = data\n",
    "        self.N = N\n",
    "        self.demanda = demanda\n",
    "\n",
    "    def _evaluate(self, x, out):\n",
    "        out['F'] = objective_func(x, self.N, self.data)\n",
    "        individual = np.delete(x, self.N * 2)\n",
    "        out['H'] = self.demanda - np.sum(individual)\n",
    "\n",
    "class TopOrZeroSampling(Sampling):\n",
    "    def __init__(self, capacidades, demanda, N):\n",
    "        super().__init__()\n",
    "        self.capacidades = capacidades\n",
    "        self.demanda = demanda\n",
    "        self.N = N\n",
    "\n",
    "    def _do(self, problem, n_samples, **kwargs):\n",
    "        gen_matrix = np.zeros((n_samples, n_var), dtype=float)\n",
    "        n_vars = self.N * 2 + 1\n",
    "        for i in range(n_samples):\n",
    "            indices = np.arange(n_vars - 1)\n",
    "            np.random.shuffle(indices)\n",
    "            while np.sum(gen_matrix[i]) < self.demanda and indices.size > 0:\n",
    "                idx = indices[0]\n",
    "                gen_matrix[i, idx] = self.capacidades[idx]\n",
    "                indices = np.delete(indices, 0)\n",
    "                if np.sum(gen_matrix[i]) > self.demanda:\n",
    "                    gen_matrix[i, idx] = gen_matrix[i, idx] - (np.sum(gen_matrix[i]) - self.demanda)\n",
    "                    break\n",
    "            gen_matrix[i, self.N * 2] = np.random.randint(self.capacidades[self.N * 2] + 1)\n",
    "        return gen_matrix\n",
    "\n",
    "class SinglePointCross(Crossover):\n",
    "    def __init__(self, prob, capacidades, demanda):\n",
    "        super().__init__(n_parents=2, n_offsprings=1, prob=prob)\n",
    "        self.capacidades = capacidades\n",
    "        self.demanda = demanda\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        _, n_matings, n_var = X.shape\n",
    "        T = np.zeros((1, n_matings, n_var))\n",
    "        Y = np.full_like(T, None, dtype=float)\n",
    "        for idx in range(n_matings):\n",
    "            p1 = X[0, idx, : n_var//2]\n",
    "            p2 = X[1, idx, n_var//2 : n_var - 1]\n",
    "            offspring = np.concatenate((p1, p2))\n",
    "            if np.sum(offspring) > self.demanda:\n",
    "                delta = np.sum(offspring) - self.demanda\n",
    "                balance(offspring, self.capacidades, delta, True)\n",
    "            else:\n",
    "                delta = self.demanda - np.sum(offspring)\n",
    "                balance(offspring, self.capacidades, delta, False)\n",
    "            for i in range(offspring.shape[0]):\n",
    "                Y[0, idx, i] = offspring[i]\n",
    "            main = np.random.choice([X[0, idx, n_var-1], X[1, idx, n_var-1]])\n",
    "            Y[0, idx, n_var-1] = main\n",
    "        return Y\n",
    "\n",
    "class ReassignMutation(Mutation):\n",
    "    def __init__(self, prob, capacidades, demanda, N):\n",
    "        super().__init__()\n",
    "        self.prob = prob\n",
    "        self.capacidades = capacidades\n",
    "        self.demanda = demanda\n",
    "        self.N = N\n",
    "\n",
    "    def _do(self, problem, X, **kwargs):\n",
    "        for i in range(len(X)):\n",
    "            r = np.random.random()\n",
    "            if r < self.prob:\n",
    "                individual = X[i]\n",
    "                idx_mut = np.random.randint(individual.shape[0])\n",
    "                if idx_mut == self.N*2:\n",
    "                    X[i, problem.n_var-1] = np.random.randint(self.capacidades[self.N * 2] + 1)\n",
    "                else:\n",
    "                    if individual[idx_mut] == 0:\n",
    "                        delta = self.capacidades[idx_mut]\n",
    "                        individual[idx_mut] = self.capacidades[idx_mut]\n",
    "                        diff = True\n",
    "                    else:\n",
    "                        delta = individual[idx_mut]\n",
    "                        individual[idx_mut] = 0\n",
    "                        diff = False\n",
    "                    balance(individual, self.capacidades, delta, diff)\n",
    "                    for j in range(individual.shape[0]):\n",
    "                        X[i, j] = individual[j]\n",
    "        return X\n",
    "\n",
    "def run_experiment(p_mutate, p_cross, pop_size, max_gen, block_name, data, N, capacidades, xl, xu, demanda, runs=100):\n",
    "    def single_run(run, p_mutate, p_cross, pop_size, max_gen):\n",
    "        t_start = timeit.default_timer()\n",
    "        algorithm = GA(\n",
    "            pop_size=pop_size,\n",
    "            sampling=TopOrZeroSampling(capacidades, demanda, N),\n",
    "            crossover=SinglePointCross(prob=p_cross, capacidades=capacidades, demanda=demanda),\n",
    "            mutation=ReassignMutation(prob=p_mutate, capacidades=capacidades, demanda=demanda, N=N),\n",
    "            eliminate_duplicates=True\n",
    "        )\n",
    "        termination = DefaultSingleObjectiveTermination(\n",
    "            xtol=1e-8,\n",
    "            cvtol=1e-6,\n",
    "            ftol=1e-6,\n",
    "            period=100, \n",
    "            n_max_gen=1000000,\n",
    "            n_max_evals=100000\n",
    "        )\n",
    "        ga = minimize(\n",
    "            Queso(data, N, demanda), \n",
    "            algorithm, \n",
    "            termination, \n",
    "            save_history=False, \n",
    "            verbose=False\n",
    "        )\n",
    "        t_end = timeit.default_timer()\n",
    "        costo = np.squeeze(ga.F) if ga.F is not None else float('inf')\n",
    "        iterations = ga.history[-1].n_gen if ga.history else 0\n",
    "        return {\n",
    "            'block': block_name,\n",
    "            'T_mutacion': p_mutate,\n",
    "            'T_cruce': p_cross,\n",
    "            'size_pob': pop_size,\n",
    "            'N_gen': max_gen,\n",
    "            'run': run + 1,\n",
    "            'costo': costo,\n",
    "            'tiempo': t_end - t_start,\n",
    "            'iteraciones': iterations\n",
    "\n",
    "        }\n",
    "    results = Parallel(n_jobs=4)(delayed(single_run)(i, p_mutate, p_cross, pop_size, max_gen) for i in range(runs))\n",
    "    return results\n",
    "\n",
    "def summarize_experiment(results):\n",
    "    df = pd.DataFrame(results)\n",
    "    summary = df.groupby(['block', 'T_mutacion', 'T_cruce', 'size_pob', 'N_gen']).agg(\n",
    "        mean=('costo', 'mean'),\n",
    "        std=('costo', 'std'),\n",
    "        avg_time=('tiempo', 'mean'),\n",
    "                avg_iterations=('iteraciones', 'mean') \n",
    "    ).reset_index()\n",
    "    summary['var.coeff'] = summary['std'] / summary['mean']\n",
    "    summary = summary[['block', 'T_mutacion', 'T_cruce', 'size_pob', 'N_gen', 'mean', 'var.coeff', 'avg_time', 'avg_iterations']]\n",
    "    return summary\n",
    "\n",
    "# parametros para los experimentos\n",
    "block1_p_mutate = [0.5, 0.7, 0.9]\n",
    "block1_p_cross = [0.5, 0.7, 0.9]\n",
    "block1_pop_size = [50, 100, 150]\n",
    "block1_max_gen = [100, 300, 500]\n",
    "\n",
    "block2_p_mutate = np.arange(0.1, 0.6, 0.1).tolist()\n",
    "block2_p_cross = np.arange(0.1, 0.8, 0.1).tolist()\n",
    "block2_pop_size = block1_pop_size\n",
    "block2_max_gen = block1_max_gen\n",
    "\n",
    "# experimentos\n",
    "all_results = []\n",
    "for p_mutate in block1_p_mutate:\n",
    "    for p_cross in block1_p_cross:\n",
    "        for pop_size in block1_pop_size:\n",
    "            for max_gen in block1_max_gen:\n",
    "                all_results.extend(run_experiment(p_mutate, p_cross, pop_size, max_gen, 'Bloque 1', data, N, capacidades, xl, xu, demanda))\n",
    "\n",
    "for p_mutate in block2_p_mutate:\n",
    "    for p_cross in block2_p_cross:\n",
    "        for pop_size in block2_pop_size:\n",
    "            for max_gen in block2_max_gen:\n",
    "                all_results.extend(run_experiment(p_mutate, p_cross, pop_size, max_gen, 'Bloque 2', data, N, capacidades, xl, xu, demanda))\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "try:\n",
    "    results_df.to_excel('experiment_results_ga.xlsx', index=False)\n",
    "    print(\"Resultados exportados a 'experiment_results_ga.xlsx' con columnas: block, T_mutacion, T_cruce, size_pob, N_gen, run, costo, tiempo, iteraciones\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al exportar 'experiment_results_ga.xlsx': {e}\")\n",
    "\n",
    "summary_df = summarize_experiment(all_results)\n",
    "try:\n",
    "    summary_df.to_excel('experiment_summary_ga.xlsx', index=False)\n",
    "    print(\"Resumen exportado a 'experiment_summary_ga.xlsx' con columnas: block, T_mutacion, T_cruce, size_pob, N_gen, mean, var.coeff, avg_time, avg_iterations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al exportar 'experiment_summary_ga.xlsx': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b98730-9a7b-48fb-be6a-3c8380de5326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
